{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по Автобрее №1\n",
    "### Настя Чижикова, БКЛ181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СИТУАЦИЯ: я написала код, который ывкачивает негативные и позитивные отзывы с сайта IRecommend, но в какой-то момент он стал меня банить за много запросов (паузы не помогали). Я переписала код совсем немного, чтобы он работал на сайте Отзовик.ру, и он работал, но потом тоже меня забанил и не хотел ничего выдавать. Поэтому в итоге я сделала корпус вручную (в приложенных файлах). Код для парсинга оставляю на память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возьмем набор отзывов о самых мультфильмах на Отзовике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "import sqlite3\n",
    "import collections\n",
    "import re\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import time\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import random\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': ua.random}\n",
    "result = requests.get('https://otzovik.com/show_filter.php?cat_id=182&f[r]=10_')\n",
    "result.encoding = 'utf-8'\n",
    "html = result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for ps in soup.find_all('a', \"product-name\"):\n",
    "    links.append(ps.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_all_reviews(link):  #  функция возвращает ссылки на полные версии отзывов\n",
    "    result = requests.get(link)\n",
    "    result.encoding = 'utf-8'\n",
    "    html = result.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    time.sleep(20)\n",
    "    \n",
    "    \n",
    "    full_reviews = []\n",
    "    for ps in soup.find_all('a', \"review-read-link\"):\n",
    "        full_reviews.append(ps.get('href'))\n",
    "        \n",
    "    print(full_reviews)\n",
    "    return full_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(link):  #  функция собирает тексты отзывов\n",
    "    neg_revs = []\n",
    "    pos_revs = []\n",
    "    \n",
    "    full_reviews = open_all_reviews(link)\n",
    "    \n",
    "    \n",
    "    for review in full_reviews:\n",
    "        time.sleep(20)\n",
    "        rev_link = \"https://otzovik.com\" + review\n",
    "        result = requests.get(rev_link)\n",
    "        print(rev_link)\n",
    "        result.encoding = 'utf-8'\n",
    "        html = result.text\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        \n",
    "        m = soup.find('meta', itemprop=\"ratingValue\")\n",
    "        rating = int(m.get('content'))\n",
    "        \n",
    "        rev_text = soup.find('div', '46pr1').contents\n",
    "            \n",
    "        if rating > 3:  #  за позитивные отзывы считаем только выше 3\n",
    "            pos_revs.append(rev_text)\n",
    "        else:\n",
    "            neg_revs.append(rev_text)\n",
    "                \n",
    "        \n",
    "                \n",
    "    return pos_revs, neg_revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-56d8b5935daa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_reviews\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_reviews\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://otzovik.com\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_reviews\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-18c4e9164210>\u001b[0m in \u001b[0;36mget_reviews\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpos_revs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mfull_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_all_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-aebce5906f37>\u001b[0m in \u001b[0;36mopen_all_reviews\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neg_reviews = []\n",
    "pos_reviews = []\n",
    "valid_reviews = [[], []]  #  выборка для проверки качества\n",
    "\n",
    "for l in links:\n",
    "    if len(neg_reviews) < 30 or len(pos_reviews) < 30 or (len(valid_reviews[0]) + len(valid_reviews[1])) < 10:\n",
    "        link = \"https://otzovik.com\" + l\n",
    "        pos, neg = get_reviews(link)\n",
    "    \n",
    "        if len(neg_reviews) < 30:\n",
    "            neg_reviews.extend(neg)\n",
    "        if len(pos_reviews) < 30:\n",
    "            pos_reviews.extend(pos)\n",
    "        \n",
    "        if len(neg_reviews) >= 30 and len(pos_reviews) >= 30:\n",
    "            if len(valid_reviews[0]) < 5:\n",
    "                valid_reviews[0].extend(neg)\n",
    "            if len(valid_reviews[1]) < 5:\n",
    "                valid_reviews[1].extend(pos)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус из ~30 негативных и ~30 позитивных отзывов на разные современные мультфильмы собран вручную с сайта Отзовик.ру, за позитивные отзывы считались отзывы с оценкой 4 или 5 звезд, за негативные - 3 и меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg_reviews.txt', encoding='utf-8') as f:\n",
    "    neg_reviews = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos_reviews.txt', encoding='utf-8') as f:\n",
    "    pos_reviews = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    words = []\n",
    "    for w in nltk.word_tokenize(text.lower()):\n",
    "        words.append(m.parse(w)[0].normal_form)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words_ = preprocess(neg_reviews)\n",
    "pos_words_ = preprocess(pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = collections.Counter()\n",
    "pos_words = collections.Counter()\n",
    "\n",
    "for w in neg_words_:\n",
    "    neg_words[w] += 1\n",
    "    \n",
    "for w in pos_words_:\n",
    "    pos_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_pos = collections.Counter()\n",
    "uni_neg = collections.Counter()\n",
    "\n",
    "for w in pos_words:  #  сохраним уникальные элементы с их частотностью\n",
    "    if w not in neg_words:\n",
    "        uni_pos[w] = pos_words[w]\n",
    "        \n",
    "for w in neg_words: \n",
    "    if w not in pos_words:\n",
    "        uni_neg[w] = neg_words[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rev):\n",
    "    rev_words = preprocess(rev)\n",
    "    vect = []  #  создаем вектор для отзыва\n",
    "    \n",
    "    for w in rev_words:\n",
    "        if w in uni_pos:\n",
    "            vect.append(1)\n",
    "        elif w in uni_neg:\n",
    "            vect.append(-1)\n",
    "        else:\n",
    "            vect.append(0)\n",
    "    \n",
    "    pred = sum(vect)\n",
    "    \n",
    "    \n",
    "    '''Если слов из \"положительного\" списка больше, сумма будет положительная, и наоборот.\n",
    "    Если слов поровну (или все слова встречаются впервые), возвращаем ноль'''\n",
    "    \n",
    "    \n",
    "    if pred > 0:\n",
    "        return 1\n",
    "    elif pred < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем accuracy на (тоже вручную собранной) валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_reviews = [[], []]\n",
    "with open('val_neg_reviews.txt', encoding='utf-8') as f:\n",
    "    neg = f.read()\n",
    "    valid_reviews[0] = neg.split('\\n\\n')\n",
    "    \n",
    "with open('val_pos_reviews.txt', encoding='utf-8') as f:\n",
    "    pos = f.read()\n",
    "    valid_reviews[1] = pos.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    acc_v = []\n",
    "\n",
    "    for r in valid_reviews[0]:\n",
    "        if predict(r) == -1:\n",
    "            acc_v.append(1)\n",
    "        elif predict(r) == 1:\n",
    "            acc_v.append(0)\n",
    "        \n",
    "    for r in valid_reviews[1]:\n",
    "        if predict(r) == -1:\n",
    "            acc_v.append(0)\n",
    "        elif predict(r) == 1:\n",
    "            acc_v.append(1)\n",
    "\n",
    "    return sum(acc_v) / len(acc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем то же самое, но сохраним только уникальные слова, встретившиеся больше одного раза (думаю, получится плохо)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_pos_ = uni_pos\n",
    "uni_neg_ = uni_neg\n",
    "\n",
    "uni_pos = collections.Counter()\n",
    "uni_neg = collections.Counter()\n",
    "\n",
    "for w in uni_pos_:\n",
    "    if uni_pos_[w] > 1:\n",
    "        uni_pos[w] = uni_pos_[w]\n",
    "        \n",
    "for w in uni_neg_:\n",
    "    if uni_neg_[w] > 1:\n",
    "        uni_neg[w] = uni_neg_[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось плохо :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Что можно было сделать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Собрать отзывы ~~как нормальный человек~~ не руками и в большем количестве (явно не хватает выборки, частотность слов не сбалансирована и иногда обусловлена сюжетом мультфильма, о котором отзыв \n",
    "1. Токенизировать не на слова, а как-то по-другому: в частности, очень хотелось бы сохранять, например, последовательность токенов \"не рекомендую\" или \"не понравилось\" (на данном этапе они разъединялись и \"сливались\" с \"рекомендую\" и \"понравилось\")\n",
    "2. Выбрать другую модель для предсказания, например, обучить логистическую регрессию, чтобы предсказание было чуть более осмысленным"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
